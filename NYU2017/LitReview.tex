\section{Prior Work on Evaluating Prosecutorial Efficiency }

 \subsection{Existing measurements of prosecution performance} 

Previous studies have examined case-processing time as a standardized
measurement allowing comparison across jurisdictions
\hyperref[csl:6]{(Klemm 1986)}. In order to use case-processing time,
researchers first must subdivide case timelines into appropriate time
frames and reduce the scope to time under the control of the court
system \hyperref[csl:7]{(Neubauer 1983)}. Early studies have also
shown that case complexities such as prior convictions, mandatory
minimums, and the number of defendants in specific jurisdictions may
contribute to the length of a case \hyperref[csl:8]{(Luskin and Luskin
  1986}; \hyperref[csl:9]{Walsh et al. 2015)}. These findings align
with the expectations of prosecutors at the SCC District Attorney's
office and form the basis for our capstone project.

In recent years, there have been other data-driven efforts to evaluate
and compare court system performance. One such effort is
\hyperref[csl:5]{({Measures for Justice} 2017)}, an initiative to
aggregate and compare the performance of criminal justice systems from
arrest to post-conviction for the entire country via an interactive
public dashboard. One of the largest challenges is that criminal
justice data are neither recorded uniformly across local jurisdictions
nor are publicly available. The solution from Measures for Justice is
to reach out individually to jurisdictions to obtain data and then
create standardized core measurements for evaluating performance.

In addition to parsing and understanding case timelines, another
motivation of this capstone is to determine whether the addition of
defendant characteristics can explain delays in resolution, which
would indicate the presence of disparities. It is widely perceived
that race/ethnic disparities pervade the criminal justice system, and
much research has been conducted on biases at the point of arrest and
police interaction \hyperref[csl:10]{(Ross 2015)}. However, no
previous work has found the presence of racial disparities in
criminal-case processing times.

\subsection{Previous analytical techniques}

Machine learning models can be helpful in decision making in the presence of a large amount of data. To be adopted by policy makers, though, they must be easily interpretable and cost-effective. Previous studies on the topic of time to disposition is dominated by linear regression and basic exploratory analysis. The use of machine learning techniques in the field of criminology is just beginning to emerge. Use of tree-based classifiers to model the outcomes of cases \cite{katz_general_2017} and advanced techniques in modeling cost-effective treatment regimes to optimize bail decisions \cite{lakkaraju_learning_2016} focus on accuracy of prediction and optimization. The employment of advanced models on case processing time could help inform prosecutors in making decisions that both minimize case length and prioritize fair outcomes.
